{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinadShegokar/Langchain/blob/main/Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "6VsvK09JKHfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ],
      "metadata": {
        "id": "oUXGztF0KJoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
        "from langchain.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding"
      ],
      "metadata": {
        "id": "8ZETglyVKOtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains import MapReduceChain, MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "HF_TOKEN = \"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\"\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "model_name=\"mistralai/Mistral-7B-v0.1\", token=HF_TOKEN\n",
        ")\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceInferenceAPIEmbeddings(api_key=HF_TOKEN,model_name=\"thenlper/gte-large\")\n",
        ")\n",
        "\n",
        "# Load PDF documents\n",
        "loader = PyPDFLoader(\"Schizophrenia.pdf\")\n",
        "docs = loader.load_and_split()\n",
        "\n",
        "# Define prompt template for MapReduce\n",
        "map_template = \"\"\"The following is a set of documents\n",
        "{docs}\n",
        "Based on this list of docs, please identify the main themes\n",
        "Helpful Answer:\"\"\"\n",
        "map_prompt = PromptTemplate.from_template(map_template)\n",
        "\n",
        "# MapReduce chain\n",
        "map_chain = MapReduceDocumentsChain(\n",
        "    llm=LLMChain(llm=llm , prompt=map_prompt,),\n",
        "    splitter=CharacterTextSplitter(),\n",
        "    map_prompt=map_prompt,\n",
        "    reduce_chain=ReduceDocumentsChain(),\n",
        ")\n",
        "\n",
        "# Define prompt template for StuffDocumentsChain\n",
        "stuff_prompt_template = \"\"\"Write a concise summary of the following in bullet points:\n",
        "```{text}```\n",
        "CONCISE SUMMARY:\"\"\"\n",
        "stuff_prompt = PromptTemplate.from_template(stuff_prompt_template)\n",
        "\n",
        "# Stuff Documents chain\n",
        "stuff_chain = StuffDocumentsChain(\n",
        "    llm_chain=LLMChain(llm=embed_model, prompt=stuff_prompt),\n",
        "    document_variable_name=\"text\"\n",
        ")\n",
        "\n",
        "# Run MapReduceChain\n",
        "mapped_reduced_docs = map_chain.run(docs)\n",
        "\n",
        "# Run StuffDocumentsChain on the output of MapReduceChain\n",
        "print(stuff_chain.run(mapped_reduced_docs))\n"
      ],
      "metadata": {
        "id": "M2jyzSQFKREg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}